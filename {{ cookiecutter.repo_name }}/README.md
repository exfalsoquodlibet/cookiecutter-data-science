# {{cookiecutter.project_name}}

==============================

{{cookiecutter.description}}

## Project Organization

------------

    ├── LICENSE
    │
    ├── Makefile                <- Makefile with commands like `make data` or `make train`
    │
    ├── README.md               <- The top-level README for developers using this project.
    │
    ├── CONTRIBUTING.md         <- Guide to how potential contributors can help with your project
    │
    ├── .env                    <- Where to declare individual user environment variables
    │
    ├── .gitignore              <- Files and directories to be ignored by git
    │
    ├── test_environment.py     <- Python environment tester   
    │
    ├── data
    │   ├── external             <- Data from third party sources.
    │   ├── interim              <- Intermediate data that has been transformed.
    │   ├── processed            <- The final, canonical data sets for modeling.
    │   └── raw                  <- The original, immutable data dump.
    │
    ├── docs                            <- A default Sphinx project; see sphinx-doc.org for details
    │   └── pull_request_template.md    <- Pull request template
    │
    ├── models                   <- Trained and serialized models, model predictions, or model summaries
    │
    ├── notebooks                <- Jupyter notebooks. Naming convention is a number (for ordering),
    │                               the creator's initials, and a short `-` delimited description, e.g.
    │                               `1.0-jqp-initial-data-exploration`.
    │
    ├── references               <- AQA plan, Assumptions log, data dictionaries, and all other explanatory materials
    │   ├── aqa_plan.md          <- AQA plan for the project
    │   └── assumptions_log.md   <- where to log key assumptions to data / models / analyses
    │
    ├── reports                  <- Generated analysis as HTML, PDF, LaTeX, etc.
    │   └── figures              <- Generated graphics and figures to be used in reporting
    │
    ├── requirements.txt         <- The requirements file for reproducing the analysis environment, e.g.
    │                               generated with `pip freeze > requirements.txt`
    │
    ├── setup.py                 <- makes project pip installable (pip install -e .) so src can be imported
    │
    ├── src                      <- Source code for use in this project.
        ├── __init__.py          <- Makes src a Python module
        │
        ├── make_data            <- Scripts to download or generate data
        │
        ├── make_features        <- Scripts to turn raw data into features for modeling
        │
        ├── make_models          <- Scripts to train models and then use trained models to make predictions
        │
        ├── make_visualisations  <- Scripts to create exploratory and results oriented visualizations
        │
        └── tools                <- Any helper scripts go here

--------

##  Installing pre-commit hooks

This repo uses the Python package `pre-commit` (https://pre-commit.com) to manage pre-commit hooks. Pre-commit hooks are
actions which are run automatically, typically on each commit, to perform some common set of tasks. For example, a
pre-commit hook might be used to run any code linting automatically, providing any warnings before code is committed,
ensuring that all of our code adheres to a certain quality standard.

For this repo, we are using `pre-commit` for a number of purposes:
- Checking for any secrets being committed accidentally
- Checking for any large files (over 5MB) being committed
- Cleaning Jupyter notebooks, which means removing all outputs and execution counts

We have configured `pre-commit` to run automatically on _every commit_. By running on each commit, we ensure
that `pre-commit` will be able to detect all contraventions and keep our repo in a healthy state.

In order for `pre-commit` to run, action is needed to configure it on your system.

- Run `pip install -r requirements-dev.txt` to install `pre-commit` in your Python environment
- Run `pre-commit install` to set-up `pre-commit` to run when code is _committed_

### Setting up a baseline for the `detect-secrets` hook (if one doesn't already exist)

The `detect-secrets` hook requires that you generate a baseline file if one is not already present within the root
directory. This is done via running the following at the root of the repo:

`detect-secrets scan > .secrets.baseline`

Next, audit the baseline that has been generated by running:

`detect-secrets audit .secrets.baseline`

When you run this command, you'll enter an interactive console and be presented with a list of high-entropy string /
anything which _could_ be a secret, and asked to verify whether or not this is the case. By doing this, the hook will
be in a position to know if you're later committing any _new_ secrets to the repo and it will be able to alert you
accordingly.

### If pre-commit detects secrets during commit:

If pre-commit detects any secrets when you try to create a commit, it will detail what it found and where to go to check
the secret.

If the detected secret is a false-positive, you should update the secrets baseline through the following steps:

- Run `detect-secrets scan --update .secrets.baseline` to index the false-positive(s)
- Next, audit all indexed secrets via `detect-secrets audit .secrets.baseline` (the same as during initial set-up, if a
secrets baseline doesn't exist)
- Finally, ensure that you commit the updated secrets baseline in the same commit as the false-positive(s) it has been
updated for

If the detected secret is actually a secret (or other sensitive information), remove the secret and re-commit. There is
no need to update the secrets baseline in this case.

If your commit contains a mixture of false-positives and actual secrets, remove the actual secrets first before
updating and auditing the secrets baseline.

###  Note on Jupyter notebook cleaning

It may be necessary or useful to keep certain output cells of a Jupyter notebook, for example charts or graphs
visualising some set of data. To do this, add the following comment at the top of the input block:

`# [keep_output]`

This will tell `pre-commit` not to strip the resulting output of this cell, allowing it to be committed.

--------

Project based on the [cookiecutter data science project template](https://drivendata.github.io/cookiecutter-data-science)
